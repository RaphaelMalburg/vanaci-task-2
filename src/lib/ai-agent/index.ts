import { generateText, streamText, CoreMessage, stepCountIs } from "ai";
import { setGlobalContext, updateGlobalContext } from "./context";
import { createLLMModel, createLLMModelWithFallback, validateLLMConfig, LLMConfig as ConfigLLMConfig } from "./config";
import { conditionalRewriteMessage } from "./message-rewriter";
import { cartTools } from "./actions/cart";
import { productTools } from "./actions/products";
import { checkoutTools } from "./actions/checkout";
import { navigationTools } from "./actions/navigation";
import { budgetTools } from "./actions/budget";
import { extraTools } from "./actions/extras";
import { logger } from "@/lib/logger";
import { SessionService } from "@/lib/services/session.service";
import type { AgentMessage, AgentSession } from "./types";
import type { LLMConfig } from "./config";

// Combinar todas as tools
export const allTools = {
  ...cartTools,
  ...productTools,
  ...checkoutTools,
  ...navigationTools,
  ...budgetTools,
  ...extraTools,
};

// Sistema de prompt para o agente
const SYSTEM_PROMPT = `Voc√™ √© um assistente virtual da Farm√°cia Vanaci. Seja amig√°vel, profissional e direto.

**REGRAS ESSENCIAIS:**
- Respostas CONCISAS e OBJETIVAS
- NUNCA mencione processos t√©cnicos, IDs, sistemas ou ferramentas
- Fale naturalmente como um farmac√™utico experiente
- Para medicamentos: sempre mencione consultar profissionais de sa√∫de
- Use emojis moderadamente

**FLUXO OBRIGAT√ìRIO PARA BUSCAS:**
1. Escolha a tool apropriada:
   - Promo√ß√µes/ofertas/descontos ‚Üí get_promotional_products
   - Dor/sintomas ‚Üí list_recommended_products  
   - Outros produtos ‚Üí search_products
2. SEMPRE execute show_multiple_products com TODOS os IDs encontrados
3. Responda de forma natural e concisa

**REGRAS DE CARRINHO:**
- Adicionar: search_products ‚Üí add_to_cart
- Remover: view_cart ‚Üí remove_from_cart
- Ver carrinho: view_cart
- Limpar: clear_cart

**ESTILO DE RESPOSTA:**
- Seja direto: "Encontrei 8 produtos para dor no joelho" (n√£o "vou buscar...")
- Confirme a√ß√µes: "Produto adicionado!" (n√£o "executando adi√ß√£o...")
- Foque no cliente, n√£o no processo

Sempre priorize o bem-estar do cliente e mantenha os padr√µes farmac√™uticos.`;

// Classe do Agente AI
export class PharmacyAIAgent {
  private llmConfig: ConfigLLMConfig;
  private sessionService: SessionService;

  constructor(llmConfig?: ConfigLLMConfig) {
    this.llmConfig = llmConfig || {
      provider: (process.env.DEFAULT_LLM_PROVIDER as ConfigLLMConfig["provider"]) || "openai",
      temperature: parseFloat(process.env.LLM_TEMPERATURE || "0.7"),
      maxTokens: parseInt(process.env.LLM_MAX_TOKENS || "2000"),
    };
    validateLLMConfig(this.llmConfig.provider);
    this.sessionService = SessionService.getInstance();
  }

  // Criar ou obter sess√£o
  private async getSession(sessionId: string): Promise<AgentSession> {
    try {
      const session = await this.sessionService.getSession(sessionId);
      if (!session) {
        logger.debug("Sess√£o n√£o encontrada, criando nova", { sessionId });
        return await this.sessionService.createSession(sessionId);
      }
      return session;
    } catch (error) {
      logger.debug("Erro ao obter sess√£o, criando nova", { sessionId });
      return await this.sessionService.createSession(sessionId);
    }
  }

  // Converter mensagens para formato CoreMessage
  private convertMessages(messages: AgentMessage[]): CoreMessage[] {
    return messages.map((msg) => ({
      role: msg.role,
      content: msg.content,
    }));
  }

  /**
   * Detecta se uma mensagem deve obrigatoriamente usar tools
   */
  private shouldForceToolUsage(message: string): boolean {
    const lowerMessage = message.toLowerCase().trim();

    // Padr√µes que SEMPRE devem usar tools
    const toolPatterns = [
      // Carrinho
      /\b(ver|mostrar|visualizar|exibir)\s+(o\s+)?carrinho\b/,
      /\b(meu|o)\s+carrinho\b/,
      /\bcarrinho\b/,
      /\blimpar?\s+carrinho\b/,
      /\besvaziar\s+carrinho\b/,

      // Adicionar produtos
      /\b(adicionar?|add|colocar?)\s+.+\s+(ao\s+)?carrinho\b/,
      /\b(adicionar?|add|colocar?)\s+\d+\s+.+/,
      /\bquero\s+(adicionar?|comprar)\b/,

      // Buscar produtos
      /\b(buscar?|procurar?|encontrar?)\s+.+/,
      /\b(tem|h√°|existe)\s+.+\?/,
      /\bonde\s+(est√°|fica)\s+.+\?/,

      // Promo√ß√µes e ofertas (SEMPRE usar get_promotional_products)
      /\b(promo√ß[√µ√£]o|promo√ß[√µ√£]es|oferta|ofertas|desconto|descontos)\b/,
      /\b(em\s+promo√ß[√£√£]o|com\s+desconto|mais\s+barato)\b/,
      /\b(pelas\s+promo√ß[√µ√£]es|produtos\s+promocionais)\b/,

      // Dor e sintomas (SEMPRE usar list_recommended_products)
      /\b(dor|rem√©dio\s+p\s+dor|rem√©dio\s+para\s+dor|analg√©sico)\b/,
      /\b(dor\s+de\s+cabe√ßa|dor\s+muscular|dor\s+nas\s+costas)\b/,
      /\b(dor\s+no\s+joelho|dor\s+articular|dor\s+de\s+garganta)\b/,

      // Remover do carrinho
      /\b(remover?|tirar|excluir)\s+.+\s+(do\s+)?carrinho\b/,
      /\b(remover?|tirar|excluir)\s+\d+\s+.+/,

      // Checkout e pagamento
      /\b(finalizar|concluir)\s+(compra|pedido)\b/,
      /\bcheckout\b/,
      /\bpagar\b/,

      // Produtos espec√≠ficos (nomes comuns)
      /\b(dipirona|paracetamol|ibuprofeno|aspirina|vitamina|term√¥metro)\b/,

      // Qualquer pergunta ou query (SEMPRE mostrar produtos)
      /\?$/,
      /\b(o\s+que|que\s+tipo|qual|quais)\b/,
    ];

    return toolPatterns.some((pattern) => pattern.test(lowerMessage));
  }

  // Processar mensagem do usu√°rio
  async processMessage(sessionId: string, userMessage: string, context?: { cartId?: string; userId?: string; user?: any; currentPage?: string }): Promise<string> {
    try {
      logger.info("Processando mensagem", { sessionId, messageLength: userMessage.length });

      // Reescrever mensagem se habilitado
      let processedMessage = userMessage;
      if (this.llmConfig.enableMessageRewriter) {
        const rewriteResult = await conditionalRewriteMessage(userMessage, this.llmConfig);
        processedMessage = rewriteResult.message;
        if (rewriteResult.wasRewritten) {
          logger.debug("Mensagem reescrita", { original: userMessage.substring(0, 50), rewritten: processedMessage.substring(0, 50) });
        }
      }

      const session = await this.getSession(sessionId);

      // Atualizar contexto se fornecido
      if (context) {
        await this.sessionService.updateSessionContext(sessionId, { ...session.context, ...context });
      }

      // Adicionar mensagem do usu√°rio
      const userMsg: AgentMessage = {
        role: "user",
        content: processedMessage,
        timestamp: new Date(),
      };
      await this.sessionService.addMessage(sessionId, userMsg, context?.userId);
      session.messages.push(userMsg);

      // Preparar mensagens para o LLM
      const messages: CoreMessage[] = [{ role: "system", content: SYSTEM_PROMPT }, ...this.convertMessages(session.messages)];

      // Gerar resposta com tools (usando fallback)
      const llmModel = await createLLMModelWithFallback(this.llmConfig);

      // Definir sessionId no contexto global para as tools
      setGlobalContext("sessionId", sessionId);
      if (context) {
        if (context.cartId) setGlobalContext("cartId", context.cartId);
        if (context.userId) setGlobalContext("userId", context.userId);
        if (context.currentPage) setGlobalContext("currentPage", context.currentPage);
        // Definir informa√ß√µes do usu√°rio no contexto global
        if (context.user) {
          setGlobalContext("user", context.user);
          logger.debug("Usu√°rio definido no contexto global", { username: context.user.username });
        }
      }

      const result = await generateText({
        model: llmModel,
        messages: messages,
        tools: allTools,
        temperature: this.llmConfig.temperature || 0.7,
        stopWhen: stepCountIs(10), // Permite at√© 10 steps para m√∫ltiplas tool calls em sequ√™ncia
      });

      const responseText = result.text;
      const toolCalls = result.toolCalls;
      const toolResults = result.toolResults;

      if (toolCalls && toolCalls.length > 0) {
        logger.debug("Tool calls executados", { count: toolCalls.length });
      }

      // Processar tool calls se existirem
      if (result.toolCalls && result.toolCalls.length > 0) {
        logger.debug("Tool calls detectados", { count: result.toolCalls.length });

        for (const toolCall of result.toolCalls) {
          logger.debug("Executando tool", { toolName: toolCall.toolName, toolCallId: toolCall.toolCallId });

          try {
            const tool = allTools[toolCall.toolName as keyof typeof allTools];
            if (!tool || !tool.execute) {
              throw new Error(`Tool ${toolCall.toolName} n√£o encontrada ou n√£o execut√°vel`);
            }
            const toolResult = await (tool.execute as any)((toolCall as any).args);
            logger.debug("Tool executado com sucesso", { toolName: toolCall.toolName });

            // Adicionar resultado da tool √† sess√£o
            session.messages.push({
              role: "assistant",
              content: `Tool ${toolCall.toolName}: ${JSON.stringify(toolResult)}`,
              timestamp: new Date(),
            } as AgentMessage);
          } catch (error) {
            logger.error("Erro ao executar tool", {
              toolName: toolCall.toolName,
              error: error instanceof Error ? error.message : "Erro desconhecido",
            });

            // Adicionar erro da tool √† sess√£o
            session.messages.push({
              role: "assistant",
              content: `Tool ${toolCall.toolName} Error: ${error instanceof Error ? error.message : "Erro desconhecido"}`,
              timestamp: new Date(),
            } as AgentMessage);
          }
        }
        logger.debug("Processamento de tool calls conclu√≠do", { count: result.toolCalls.length });
      }

      // Adicionar resposta do assistente
      const assistantMsg: AgentMessage = {
        role: "assistant",
        content: responseText,
        timestamp: new Date(),
        toolCalls: toolCalls,
      };
      await this.sessionService.addMessage(sessionId, assistantMsg, context?.userId);
      session.messages.push(assistantMsg);
      console.log("‚ûï Resposta do assistente adicionada √† sess√£o");

      // Limitar hist√≥rico de mensagens (manter √∫ltimas 20)
      if (session.messages.length > 20) {
        session.messages = session.messages.slice(-20);
        console.log("üóÇÔ∏è Hist√≥rico limitado a 20 mensagens");
      }

      console.log("‚úÖ ProcessMessage conclu√≠do com sucesso");
      return responseText;
    } catch (error) {
      console.error("‚ùå Erro ao processar mensagem:", error);
      console.error("‚ùå Stack trace:", error instanceof Error ? error.stack : "Stack n√£o dispon√≠vel");
      return "Desculpe, ocorreu um erro interno. Tente novamente em alguns instantes ou entre em contato conosco pelo telefone (11) 1234-5678.";
    }
  }

  // Processar mensagem com streaming
  async streamMessage(sessionId: string, userMessage: string, context?: { cartId?: string; userId?: string; user?: any; currentPage?: string }) {
    // Valida√ß√£o de entrada
    if (!sessionId || typeof sessionId !== "string" || sessionId.trim().length === 0) {
      const error = new Error("SessionId √© obrigat√≥rio e deve ser uma string n√£o vazia");
      logger.error("Erro de valida√ß√£o no streamMessage:", error);
      throw error;
    }

    if (!userMessage || typeof userMessage !== "string" || userMessage.trim().length === 0) {
      const error = new Error("Mensagem do usu√°rio √© obrigat√≥ria e deve ser uma string n√£o vazia");
      logger.error("Erro de valida√ß√£o no streamMessage:", error);
      throw error;
    }

    if (userMessage.length > 10000) {
      const error = new Error("Mensagem do usu√°rio muito longa (m√°ximo 10000 caracteres)");
      logger.error("Erro de valida√ß√£o no streamMessage:", error);
      throw error;
    }

    try {
      console.log("üéØ StreamMessage iniciado para sess√£o:", sessionId);
      console.log("üí¨ Mensagem original do usu√°rio:", userMessage);
      console.log("üîß Contexto fornecido:", context);

      // Reescrever mensagem se habilitado
      let processedMessage = userMessage;
      if (this.llmConfig.enableMessageRewriter) {
        const rewriteResult = await conditionalRewriteMessage(userMessage, this.llmConfig);
        processedMessage = rewriteResult.message;
        if (rewriteResult.wasRewritten) {
          logger.debug("Mensagem reescrita", { original: userMessage, rewritten: processedMessage });
        }
      }

      const session = await this.getSession(sessionId);
      logger.debug("Sess√£o obtida", { sessionId, messageCount: session.messages.length });

      // Atualizar contexto se fornecido
      if (context) {
        await this.sessionService.updateSessionContext(sessionId, { ...session.context, ...context });
        logger.debug("Contexto atualizado", { sessionId, context });
      }

      // Adicionar mensagem do usu√°rio
      const userMsg: AgentMessage = {
        role: "user",
        content: processedMessage,
        timestamp: new Date(),
      };
      await this.sessionService.addMessage(sessionId, userMsg, context?.userId);
      session.messages.push(userMsg);
      logger.debug("Mensagem do usu√°rio adicionada", { sessionId });

      // Preparar mensagens para o LLM
      const messages: CoreMessage[] = [{ role: "system", content: SYSTEM_PROMPT }, ...this.convertMessages(session.messages)];
      logger.debug("Mensagens preparadas para LLM", { count: messages.length });

      // Gerar resposta com streaming (usando fallback)
      const llmModel = await createLLMModelWithFallback(this.llmConfig);
      logger.debug("Modelo LLM criado", { hasModel: !!llmModel, toolCount: Object.keys(allTools).length });

      // Definir sessionId no contexto global para as tools
      setGlobalContext("sessionId", sessionId);
      if (context) {
        if (context.cartId) setGlobalContext("cartId", context.cartId);
        if (context.userId) {
          setGlobalContext("userId", context.userId);
          logger.debug("UserId definido no contexto", { userId: context.userId });
        }
        if (context.user) {
          setGlobalContext("user", context.user);
          logger.debug("User definido no contexto", { user: context.user });
        }
        if (context.currentPage) setGlobalContext("currentPage", context.currentPage);
      }
      logger.debug("Contexto global configurado", { sessionId });

      // Detectar se a mensagem requer tools obrigatoriamente
      const requiresTools = this.shouldForceToolUsage(processedMessage);
      logger.debug("Iniciando processamento", {
        sessionId,
        message: processedMessage,
        requiresTools,
        toolCount: Object.keys(allTools).length,
      });

      const result = streamText({
        model: llmModel,
        messages,
        tools: allTools,
        temperature: this.llmConfig.temperature || 0.7,
        toolChoice: requiresTools ? "required" : "auto",
      });

      // Processar tool calls do resultado com suporte a m√∫ltiplas execu√ß√µes
      let executionCount = 0;
      const maxExecutions = 3; // Limite para evitar loops infinitos
      const productSearchTools = ['search_products', 'get_promotional_products', 'list_recommended_products', 'get_best_sellers'];

      for await (const part of result.fullStream) {
        if (part.type === "tool-call") {
          executionCount++;
          logger.debug("Tool call executada", {
            toolName: part.toolName,
            execution: executionCount,
            toolCallId: part.toolCallId,
            args: (part as any).input,
          });

          try {
            logger.debug("Executando tool", { toolName: part.toolName });
            const tool = allTools[part.toolName as keyof typeof allTools];
            if (!tool || !tool.execute) {
              throw new Error(`Tool ${part.toolName} n√£o encontrada ou n√£o execut√°vel`);
            }
            const toolResult = await (tool.execute as any)((part as any).input);
            logger.debug("Tool executada com sucesso", {
              toolName: part.toolName,
              result: toolResult,
            });

            // N√ÉO adicionar resultado da tool √† sess√£o para evitar vazamento de informa√ß√µes t√©cnicas
            // Apenas fazer log interno para debugging
            
            // Executar show_multiple_products automaticamente ap√≥s tools de busca
            logger.debug("Verificando se deve executar show_multiple_products", {
              toolName: part.toolName,
              isProductSearchTool: productSearchTools.includes(part.toolName),
              hasToolResult: !!toolResult,
              hasData: !!toolResult?.data,
              hasProducts: !!toolResult?.data?.products,
              productCount: toolResult?.data?.products?.length || 0
            });
            
            if (productSearchTools.includes(part.toolName)) {
              logger.debug("Tool de busca de produtos detectada", { toolName: part.toolName });
              
              if (toolResult?.data?.products && toolResult.data.products.length > 0) {
                const products = toolResult.data.products;
                try {
                  const productIds = products.map((p: any) => p.id).filter(Boolean);
                  logger.debug("Produtos encontrados para overlay", { 
                    toolName: part.toolName, 
                    productIds,
                    productCount: productIds.length,
                    products: products.map((p: any) => ({ id: p.id, name: p.name }))
                  });
                  
                  if (productIds.length > 0) {
                    const showMultipleTool = allTools.show_multiple_products;
                    if (showMultipleTool && showMultipleTool.execute) {
                      logger.debug("Executando show_multiple_products automaticamente", { 
                        productIds,
                        title: "Produtos Encontrados",
                        query: processedMessage
                      });
                      
                      const overlayResult = await (showMultipleTool.execute as any)({
                        productIds,
                        title: "Produtos Encontrados",
                        query: processedMessage
                      });
                      
                      logger.debug("show_multiple_products executado com sucesso", { 
                        productCount: productIds.length,
                        overlayResult 
                      });
                    } else {
                      logger.error("show_multiple_products tool n√£o encontrada ou n√£o execut√°vel");
                    }
                  } else {
                    logger.warn("Nenhum ID de produto v√°lido encontrado", { products });
                  }
                } catch (error) {
                  logger.error("Erro ao executar show_multiple_products automaticamente", { 
                    toolName: part.toolName,
                    error: error instanceof Error ? error.message : error,
                    stack: error instanceof Error ? error.stack : undefined
                  });
                }
              } else {
                logger.warn("Tool de busca n√£o retornou produtos", {
                  toolName: part.toolName,
                  toolResult: toolResult?.data
                });
              }
            }

            // Tools ser√£o executadas naturalmente pelo LLM conforme o prompt
          } catch (error) {
            logger.error("Erro na execu√ß√£o da tool", {
              toolName: part.toolName,
              error: error instanceof Error ? error.message : error,
            });

            // N√ÉO adicionar erro da tool √† sess√£o para evitar vazamento de informa√ß√µes t√©cnicas
            // Apenas fazer log interno
          }
        } else if (part.type === "text-delta") {
          // Log silencioso para text-delta
        } else {
          logger.debug("Stream part processado", { type: part.type });
        }
      }

      logger.debug("Processamento conclu√≠do", {
        sessionId,
        totalMessages: session.messages.length,
      });

      return result;
    } catch (error) {
      logger.error("Erro ao processar mensagem com streaming:", {
        sessionId,
        userMessage: userMessage.substring(0, 100) + (userMessage.length > 100 ? "..." : ""),
        context,
        error:
          error instanceof Error
            ? {
                message: error.message,
                stack: error.stack,
                name: error.name,
              }
            : error,
      });

      // Error j√° logado pelo logger.error acima

      // Re-throw validation errors as-is
      if (error instanceof Error && error.message.includes("valida√ß√£o")) {
        throw error;
      }

      // For other errors, provide a more user-friendly message
      throw new Error("Erro interno ao processar mensagem. Tente novamente.");
    }
  }

  // Obter hist√≥rico da sess√£o
  async getSessionHistory(sessionId: string): Promise<AgentMessage[]> {
    try {
      const session = await this.sessionService.getSession(sessionId);
      return session ? [...session.messages] : [];
    } catch (error) {
      logger.error("Erro ao obter hist√≥rico da sess√£o", { sessionId, error });
      return [];
    }
  }

  // Limpar sess√£o
  async clearSession(sessionId: string): Promise<void> {
    try {
      await this.sessionService.deleteSession(sessionId);
      logger.info("Sess√£o limpa com sucesso", { sessionId });
    } catch (error) {
      logger.error("Erro ao limpar sess√£o", { sessionId, error });
      throw new Error(`Falha ao limpar sess√£o: ${error instanceof Error ? error.message : "Erro desconhecido"}`);
    }
  }

  // Obter contexto da sess√£o
  async getSessionContext(sessionId: string): Promise<Record<string, any>> {
    try {
      const session = await this.sessionService.getSession(sessionId);
      return session ? { ...session.context } : {};
    } catch (error) {
      logger.error("Erro ao obter contexto da sess√£o", { sessionId, error });
      return {};
    }
  }

  // Atualizar configura√ß√£o do LLM
  updateLLMConfig(newConfig: Partial<ConfigLLMConfig>): void {
    this.llmConfig = { ...this.llmConfig, ...newConfig };
    validateLLMConfig(this.llmConfig.provider);
  }

  // Obter configura√ß√£o atual do LLM
  getLLMConfig(): ConfigLLMConfig {
    return { ...this.llmConfig };
  }
}

// Inst√¢ncia singleton do agente
let agentInstance: PharmacyAIAgent | null = null;

// Fun√ß√£o para obter inst√¢ncia do agente
export function getPharmacyAgent(config?: ConfigLLMConfig): PharmacyAIAgent {
  if (!agentInstance) {
    agentInstance = new PharmacyAIAgent(config);
  }
  return agentInstance;
}

// Fun√ß√£o utilit√°ria para processar mensagem rapidamente
export async function processUserMessage(
  sessionId: string,
  message: string,
  context?: { cartId?: string; userId?: string; user?: any; currentPage?: string },
  llmConfig?: ConfigLLMConfig
): Promise<string> {
  try {
    // Validar entrada
    if (!sessionId || typeof sessionId !== "string") {
      throw new Error("SessionId √© obrigat√≥rio e deve ser uma string");
    }

    if (!message || typeof message !== "string" || message.trim().length === 0) {
      throw new Error("Mensagem √© obrigat√≥ria e n√£o pode estar vazia");
    }

    if (message.length > 10000) {
      throw new Error("Mensagem muito longa (m√°ximo 10.000 caracteres)");
    }

    const agent = getPharmacyAgent(llmConfig);
    return await agent.processMessage(sessionId, message.trim(), context);
  } catch (error) {
    logger.error("Erro na fun√ß√£o processUserMessage", { sessionId, messageLength: message?.length, error });

    if (error instanceof Error && error.message.includes("obrigat√≥rio")) {
      throw error; // Re-throw validation errors
    }

    return "Desculpe, ocorreu um erro interno. Tente novamente em alguns instantes ou entre em contato conosco pelo telefone (11) 1234-5678.";
  }
}

// Exportar types e tools
export * from "./types";
export * from "./config";
export { cartTools, productTools, checkoutTools, navigationTools, budgetTools, extraTools };