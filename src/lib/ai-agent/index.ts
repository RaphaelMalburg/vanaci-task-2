import { generateText, streamText, ModelMessage, stepCountIs } from "ai";
import { setGlobalContext, updateGlobalContext } from "./context";
import { createLLMModel, createLLMModelWithFallback, validateLLMConfig, LLMConfig as ConfigLLMConfig } from "./config";
import { conditionalRewriteMessage } from "./message-rewriter";
import { cartTools } from "./actions/cart";
import { productTools } from "./actions/products";
import { checkoutTools } from "./actions/checkout";
import { navigationTools } from "./actions/navigation";
import { budgetTools } from "./actions/budget";
import { extraTools } from "./actions/extras";
import { logger } from "@/lib/logger";
import { SessionService } from "@/lib/services/session.service";
import type { AgentMessage, AgentSession } from "@/lib/types";

// In-memory cache for session context to reduce database calls
const sessionCache = new Map<string, AgentSession>();
import type { LLMConfig } from "./config";

// Combinar todas as tools
export const allTools = {
  ...cartTools,
  ...productTools,
  ...checkoutTools,
  ...navigationTools,
  ...budgetTools,
  ...extraTools,
};

// Sistema de prompt para o agente
const SYSTEM_PROMPT = `INSTRU√á√ÉO CR√çTICA: Voc√™ DEVE SEMPRE fornecer uma resposta textual ap√≥s executar qualquer tool. NUNCA termine uma conversa apenas com tool calls.

Voc√™ √© o assistente virtual da Farm√°cia Vanaci. Seja amig√°vel, profissional e direto.

**REGRAS ESSENCIAIS:**
- Respostas CONCISAS e OBJETIVAS
- NUNCA mencione processos t√©cnicos, IDs, sistemas ou ferramentas
- Fale naturalmente como um farmac√™utico experiente
- Para medicamentos: sempre mencione consultar profissionais de sa√∫de
- Use emojis moderadamente

**FLUXO OBRIGAT√ìRIO PARA BUSCAS:**
1. Para medicamentos espec√≠ficos (ex: dipirona, paracetamol, ibuprofeno) ‚Üí use search_products
2. Para sintomas ou necessidades gerais (ex: dor de cabe√ßa, gripe) ‚Üí use list_recommended_products
3. Para promo√ß√µes/ofertas/descontos ‚Üí use get_promotional_products
4. Para outros produtos ‚Üí use search_products
5. **OBRIGAT√ìRIO**: SEMPRE que usar search_products, list_recommended_products, get_promotional_products ou get_best_sellers, voc√™ DEVE imediatamente usar show_multiple_products com os IDs dos produtos encontrados. Isso √© ESSENCIAL para que os produtos apare√ßam no overlay.
6. Responda de forma natural e concisa, destacando nome, dosagem, pre√ßo e descri√ß√£o breve em cada item

**EXEMPLO DE FLUXO CORRETO:**
- Usu√°rio: "preciso de paracetamol"
- Voc√™: search_products(query: "paracetamol") ‚Üí show_multiple_products(productIds: ["id1", "id2", "id3"]) ‚Üí RESPOSTA TEXTUAL: "Encontrei 3 op√ß√µes de paracetamol para voc√™:"
- Usu√°rio: "dor de cabe√ßa"
- Voc√™: list_recommended_products(symptomOrNeed: "dor de cabe√ßa") ‚Üí show_multiple_products(productIds: ["id1", "id2", "id3"]) ‚Üí RESPOSTA TEXTUAL: "Para dor de cabe√ßa, recomendo:"

**IMPORTANTE**: Ap√≥s usar qualquer tool, voc√™ DEVE SEMPRE gerar uma resposta textual amig√°vel. NUNCA termine a conversa apenas com tool calls - sempre forne√ßa uma resposta em texto natural para o usu√°rio.

**FLUXO OBRIGAT√ìRIO PARA CARRINHO:**
1. Quando usu√°rio quer adicionar produto (qualquer linguagem: "adicionar", "quero", "comprar", "add mais", etc.):
   a) **PRIMEIRO**: SEMPRE use search_products para encontrar TODOS os produtos mencionados pelo usu√°rio
      - Se usu√°rio mencionar m√∫ltiplos produtos (ex: "2 benuron e 2 √°lcool gel"), fa√ßa uma busca separada para CADA produto
      - Exemplo: search_products("benuron") E search_products("√°lcool gel")
   b) **SEGUNDO**: use view_cart para verificar conte√∫do atual
   c) **TERCEIRO**: Para cada produto encontrado:
      - Se produto J√Å EXISTE no carrinho ‚Üí use increment_cart
      - Se produto N√ÉO EXISTE no carrinho ‚Üí use add_to_cart
   d) **QUARTO**: SEMPRE complete o processo para TODOS os produtos solicitados antes de gerar resposta final
2. Para remover: view_cart ‚Üí remove_from_cart
3. Para ver carrinho: view_cart
4. Para limpar: clear_cart

**IMPORTANTE:**
- **NUNCA use add_to_cart ou increment_cart sem PRIMEIRO usar search_products para obter os IDs dos produtos**
- **SEMPRE use os IDs EXATOS retornados no campo 'data.products[].id' dos resultados de search_products**
- **NUNCA invente, modifique ou crie IDs de produtos - use APENAS os IDs retornados pela busca**
- SEMPRE busque TODOS os produtos mencionados antes de tentar adicion√°-los ao carrinho
- SEMPRE verifique se o produto j√° existe antes de decidir add_to_cart vs increment_cart
- A decis√£o n√£o depende da linguagem do usu√°rio, mas sim do conte√∫do atual do carrinho
- Se n√£o encontrar um produto na busca, informe ao usu√°rio que o produto n√£o est√° dispon√≠vel
- **NUNCA pare o processo no meio - complete TODOS os produtos solicitados**

**ESTILO DE RESPOSTA:**
- Use frases diretas: ex. "Encontrei 2 op√ß√µes de Dipirona para voc√™:"
- Formate a lista no overlay com bullets, incluindo dosagem e pre√ßo: ex. "‚Ä¢ Dipirona 500‚ÄØmg (com 10 comprimidos) ‚Äì ‚Ç¨4,95"
- Confirme a√ß√µes de carrinho: ex. "‚úÖ Dipirona 500‚ÄØmg adicionada ao seu carrinho."
- Foque no cliente, n√£o no processo

Sempre priorize o bem-estar do cliente e mantenha padr√µes farmac√™uticos.

**REGRA CR√çTICA DE RESPOSTA:**
- SEMPRE termine suas intera√ß√µes com uma resposta textual clara e amig√°vel
- NUNCA deixe o usu√°rio sem resposta ap√≥s executar tools
- Mesmo ap√≥s adicionar produtos ao carrinho, confirme a a√ß√£o com texto
- Se executar m√∫ltiplas tools, resuma o que foi feito em uma resposta final`;

// Classe do Agente AI
export class PharmacyAIAgent {
  private llmConfig: ConfigLLMConfig;
  private sessionService: SessionService;

  constructor(llmConfig?: ConfigLLMConfig) {
    this.llmConfig = llmConfig || {
      provider: (process.env.DEFAULT_LLM_PROVIDER as ConfigLLMConfig["provider"]) || "openrouter",
      temperature: parseFloat(process.env.LLM_TEMPERATURE || "0.7"),
      maxTokens: parseInt(process.env.LLM_MAX_TOKENS || "2000"),
    };
    validateLLMConfig(this.llmConfig.provider);
    this.sessionService = SessionService.getInstance();
  }

  // Criar ou obter sess√£o
  private async getSession(sessionId: string): Promise<AgentSession> {
    // Check in-memory cache first
    if (sessionCache.has(sessionId)) {
      return sessionCache.get(sessionId)!;
    }
    try {
      const session = await this.sessionService.getSession(sessionId);
      if (!session) {
        logger.debug("Sess√£o n√£o encontrada, criando nova", { sessionId });
        const newSession = await this.sessionService.createSession(sessionId);
        sessionCache.set(sessionId, newSession);
        return newSession;
      }
      sessionCache.set(sessionId, session);
      return session;
    } catch (error) {
      logger.debug("Erro ao obter sess√£o, criando nova", { sessionId });
      const newSession = await this.sessionService.createSession(sessionId);
      sessionCache.set(sessionId, newSession);
      return newSession;
    }
  }

  // Converter mensagens para formato ModelMessage
  private convertMessages(messages: AgentMessage[]): ModelMessage[] {
    return messages
      .filter((msg) => {
        // Filtrar mensagens v√°lidas
        return msg.content && 
               typeof msg.content === 'string' && 
               msg.content.trim() !== '' && 
               !msg.toolCalls &&
               ['system', 'user', 'assistant'].includes(msg.role);
      })
      .map((msg) => {
        if (msg.role === 'system') {
          return {
            role: 'system',
            content: msg.content,
          };
        } else if (msg.role === 'user') {
          return {
            role: 'user',
            content: msg.content,
          };
        } else if (msg.role === 'assistant') {
          return {
            role: 'assistant',
            content: msg.content,
          };
        }
        // Fallback para casos n√£o esperados
        return {
          role: 'user',
          content: msg.content,
        };
      });
  }

  /**
   * Gera uma resposta fallback din√¢mica baseada no contexto
   */
  private generateDynamicFallback(userMessage: string, currentMessages: ModelMessage[]): string {
    const lowerMessage = userMessage.toLowerCase();
    
    // Extrair informa√ß√µes de produtos das mensagens anteriores
    const productMentions = currentMessages
      .filter(msg => msg.content && typeof msg.content === 'string')
      .map(msg => msg.content as string)
      .join(' ')
      .toLowerCase();
    
    // Respostas baseadas em sintomas/necessidades
    if (lowerMessage.includes('dor') && (lowerMessage.includes('cabe√ßa') || lowerMessage.includes('cabeca'))) {
      return "Para dor de cabe√ßa, temos v√°rias op√ß√µes eficazes dispon√≠veis. Recomendo consultar nosso farmac√™utico para a melhor escolha baseada no seu caso espec√≠fico.";
    }
    
    if (lowerMessage.includes('dor') && lowerMessage.includes('barriga')) {
      return "Para desconforto abdominal, temos produtos que podem ajudar. √â importante identificar a causa - recomendo falar com nosso farmac√™utico para orienta√ß√£o adequada.";
    }
    
    if (lowerMessage.includes('gripe') || lowerMessage.includes('resfriado')) {
      return "Para sintomas de gripe e resfriado, temos uma linha completa de produtos. Posso ajudar voc√™ a encontrar o mais adequado para seus sintomas espec√≠ficos.";
    }
    
    // Respostas baseadas em medicamentos espec√≠ficos
    if (lowerMessage.includes('paracetamol')) {
      return "Temos diferentes apresenta√ß√µes de paracetamol dispon√≠veis. Cada uma tem suas caracter√≠sticas espec√≠ficas - posso ajudar voc√™ a escolher a mais adequada.";
    }
    
    if (lowerMessage.includes('dipirona')) {
      return "A dipirona √© um analg√©sico muito eficaz. Temos v√°rias op√ß√µes dispon√≠veis com diferentes dosagens e apresenta√ß√µes.";
    }
    
    if (lowerMessage.includes('ibuprofeno')) {
      return "O ibuprofeno √© excelente para dor e inflama√ß√£o. Temos diferentes marcas e dosagens dispon√≠veis em nossa farm√°cia.";
    }
    
    // Respostas para carrinho
    if (lowerMessage.includes('carrinho') || lowerMessage.includes('comprar')) {
      return "Posso ajudar voc√™ com seu carrinho de compras. Me diga qual produto gostaria de adicionar ou se precisa ver o que j√° est√° selecionado.";
    }
    
    // Resposta gen√©rica mais variada
    const genericResponses = [
      "Estou aqui para ajudar voc√™ a encontrar os produtos que precisa. Pode me contar mais sobre o que est√° procurando?",
      "Nossa farm√°cia tem uma ampla variedade de produtos. Como posso ajudar voc√™ hoje?",
      "Posso ajudar voc√™ a encontrar medicamentos e produtos de sa√∫de. Qual √© sua necessidade espec√≠fica?",
      "Estou √† disposi√ß√£o para orientar sobre nossos produtos. Me conte o que voc√™ est√° buscando."
    ];
    
    // Usar timestamp para variar a resposta
    const responseIndex = Math.floor(Date.now() / 10000) % genericResponses.length;
    return genericResponses[responseIndex];
  }

  /**
   * Detecta se uma mensagem deve obrigatoriamente usar tools
   */
  private shouldForceToolUsage(message: string): boolean {
    const lowerMessage = message.toLowerCase().trim();

    // Padr√µes que SEMPRE devem usar tools
    const toolPatterns = [
      // Carrinho
      /\b(ver|mostrar|visualizar|exibir)\s+(o\s+)?carrinho\b/,
      /\b(meu|o)\s+carrinho\b/,
      /\bcarrinho\b/,
      /\blimpar?\s+carrinho\b/,
      /\besvaziar\s+carrinho\b/,

      // Adicionar produtos
      /\b(adicionar?|add|colocar?)\s+.+\s+(ao\s+)?carrinho\b/,
      /\b(adicionar?|add|colocar?)\s+\d+\s+.+/,
      /\bquero\s+(adicionar?|comprar)\b/,

      // Incrementar quantidade no carrinho
      /\b(adicionar?|add)\s+(mais|more)\s+\d+\b/,
      /\b(mais|more)\s+\d+\s+.+/,
      /\bincrement(ar)?\b/,

      // Buscar produtos
      /\b(buscar?|procurar?|encontrar?)\s+.+/,
      /\b(tem|h√°|existe)\s+.+\?/,
      /\bonde\s+(est√°|fica)\s+.+\?/,

      // Promo√ß√µes e ofertas (SEMPRE usar get_promotional_products)
      /\b(promo√ß[√µ√£]o|promo√ß[√µ√£]es|oferta|ofertas|desconto|descontos)\b/,
      /\b(em\s+promo√ß[√£√£]o|com\s+desconto|mais\s+barato)\b/,
      /\b(pelas\s+promo√ß[√µ√£]es|produtos\s+promocionais)\b/,

      // Dor e sintomas (SEMPRE usar list_recommended_products)
      /\b(dor|rem√©dio\s+p\s+dor|rem√©dio\s+para\s+dor|analg√©sico)\b/,
      /\b(dor\s+de\s+cabe√ßa|dor\s+muscular|dor\s+nas\s+costas)\b/,
      /\b(dor\s+no\s+joelho|dor\s+articular|dor\s+de\s+garganta)\b/,

      // Remover do carrinho
      /\b(remover?|tirar|excluir)\s+.+\s+(do\s+)?carrinho\b/,
      /\b(remover?|tirar|excluir)\s+\d+\s+.+/,

      // Checkout e pagamento
      /\b(finalizar|concluir)\s+(compra|pedido)\b/,
      /\bcheckout\b/,
      /\bpagar\b/,

      // Produtos espec√≠ficos (nomes comuns)
      /\b(dipirona|paracetamol|ibuprofeno|aspirina|vitamina|term√¥metro)\b/,

      // Qualquer pergunta ou query (SEMPRE mostrar produtos)
      /\?$/,
      /\b(o\s+que|que\s+tipo|qual|quais)\b/,
    ];

    return toolPatterns.some((pattern) => pattern.test(lowerMessage));
  }

  // Processar mensagem do usu√°rio
  async processMessage(sessionId: string, userMessage: string, context?: { cartId?: string; userId?: string; user?: any; currentPage?: string }): Promise<string> {
    try {
      logger.info("Processando mensagem", { sessionId, messageLength: userMessage.length });

      // Reescrever mensagem se habilitado
      let processedMessage = userMessage;
      if (this.llmConfig.enableMessageRewriter) {
        const rewriteResult = await conditionalRewriteMessage(userMessage, this.llmConfig);
        processedMessage = rewriteResult.message;
        if (rewriteResult.wasRewritten) {
          logger.debug("Mensagem reescrita", { original: userMessage.substring(0, 50), rewritten: processedMessage.substring(0, 50) });
        }
      }

      const session = await this.getSession(sessionId);

      // Atualizar contexto se fornecido
      if (context) {
        await this.sessionService.updateSessionContext(sessionId, { ...session.context, ...context });
      }

      // Adicionar mensagem do usu√°rio
      const userMsg: AgentMessage = {
        role: "user",
        content: processedMessage,
        timestamp: new Date(),
      };
      await this.sessionService.addMessage(sessionId, userMsg, context?.userId);
      session.messages.push(userMsg);

      // Preparar mensagens para o LLM
      const convertedMessages = this.convertMessages(session.messages);
      console.log('üîç Converted messages:', JSON.stringify(convertedMessages, null, 2));
      
      let currentMessages: ModelMessage[] = [
        { role: "system", content: SYSTEM_PROMPT },
        ...convertedMessages,
      ];
      
      console.log('üîç Current messages structure:', JSON.stringify(currentMessages.map(m => ({ role: m.role, contentType: typeof m.content })), null, 2));

      // Gerar resposta com tools (usando fallback)
      const llmModel = await createLLMModelWithFallback(this.llmConfig);

      // Definir sessionId no contexto global para as tools
      setGlobalContext("sessionId", sessionId);
      if (context) {
        if (context.cartId) setGlobalContext("cartId", context.cartId);
        if (context.userId) setGlobalContext("userId", context.userId);
        if (context.currentPage) setGlobalContext("currentPage", context.currentPage);
        // Definir informa√ß√µes do usu√°rio no contexto global
        if (context.user) {
          setGlobalContext("user", context.user);
          logger.debug("Usu√°rio definido no contexto global", { username: context.user.username });
        }
      }
      let finalResponseText = "";
      let maxIterations = 5; // Limite para evitar loops infinitos
      let iteration = 0;

      while (iteration < maxIterations) {
        iteration++;
        console.log(`üîÑ Itera√ß√£o ${iteration}/${maxIterations}`);

        let result;
        try {
          // Filtrar mensagens v√°lidas para o modelo
          const validMessages = currentMessages.filter(msg => {
            return msg.role && 
                   msg.content && 
                   typeof msg.content === 'string' && 
                   msg.content.trim() !== '' &&
                   ['system', 'user', 'assistant'].includes(msg.role);
          });
          
          console.log(`üîç Valid messages for generateText (iteration ${iteration}):`, validMessages.length);
          
          result = await generateText({
            model: llmModel,
            messages: validMessages,
            tools: allTools,
            temperature: this.llmConfig.temperature || 0.7,
          });

          console.log('üîç Resultado do generateText:', {
            hasText: !!result.text,
            textLength: result.text ? result.text.length : 0,
            hasToolCalls: !!result.toolCalls,
            toolCallsCount: result.toolCalls ? result.toolCalls.length : 0
          });
        } catch (error) {
          console.error(`‚ùå Erro no generateText (itera√ß√£o ${iteration}):`, error);
          finalResponseText = "Desculpe, ocorreu um erro interno. Tente novamente em alguns instantes ou entre em contato conosco pelo telefone (11) 1234-5678.";
          break;
        }



        // Se temos texto, usar como resposta final
        if (result.text && result.text.trim()) {
          finalResponseText = result.text;
          console.log('‚úÖ Resposta textual encontrada:', JSON.stringify(finalResponseText));
        }

        // Processar tool calls se existirem
        if (result.toolCalls && result.toolCalls.length > 0) {
          console.log('üîß Tool calls detectados:', result.toolCalls.map(tc => ({ name: tc.toolName, id: tc.toolCallId })));
          
          // Adicionar mensagem do assistente com tool calls
          if (result.text || (result.toolCalls && result.toolCalls.length > 0)) {
            const assistantContent = [];
            if (result.text) {
              assistantContent.push({ type: 'text', text: result.text });
            }
            if (result.toolCalls) {
              result.toolCalls.forEach(toolCall => {
                console.log('üîç ToolCall structure:', {
                  "type": "tool-call",
                  "toolCallId": toolCall.toolCallId,
                  "toolName": toolCall.toolName,
                  "input": (toolCall as any).args || {}
                });
                
                assistantContent.push({
                  type: 'tool-call',
                  toolCallId: toolCall.toolCallId,
                  toolName: toolCall.toolName,
                  input: (toolCall as any).args || {}
                });
              });
            }
            
            // Converter assistantContent para string simples
            let contentString = '';
            if (result.text) {
              contentString = result.text;
            }
            if (result.toolCalls && result.toolCalls.length > 0) {
              const toolCallsInfo = result.toolCalls.map(tc => `[Tool: ${tc.toolName}]`).join(' ');
              contentString = contentString ? `${contentString} ${toolCallsInfo}` : toolCallsInfo;
            }
            
            currentMessages.push({
              role: 'assistant',
              content: contentString || '[Tool calls executed]'
            } as ModelMessage);
          }

          // Executar cada tool call
          for (const toolCall of result.toolCalls) {
            console.log(`üîß Executando tool: ${toolCall.toolName}`);
            console.log(`üîç ToolCall structure:`, JSON.stringify(toolCall, null, 2));

            try {
              const tool = allTools[toolCall.toolName as keyof typeof allTools];
              if (!tool || !tool.execute) {
                throw new Error(`Tool ${toolCall.toolName} n√£o encontrada ou n√£o execut√°vel`);
              }
              const toolArgs = (toolCall as any).input || (toolCall as any).args || (toolCall as any).parameters;
              console.log(`üîç Tool args:`, JSON.stringify(toolArgs, null, 2));
              const toolResult = await (tool.execute as any)(toolArgs);
              console.log(`‚úÖ Tool ${toolCall.toolName} executada com sucesso`);
              console.log(`üîç Tool result:`, JSON.stringify(toolResult, null, 2));

              // Adicionar resultado da tool √†s mensagens
             // Converter tool result para string simples
             const toolResultString = `Tool ${toolCall.toolName} result: ${JSON.stringify(toolResult)}`;
             currentMessages.push({
                role: 'assistant',
                content: toolResultString
              } as ModelMessage);

              // Adicionar resultado da tool √† sess√£o
              session.messages.push({
                role: "assistant",
                content: `Tool ${toolCall.toolName}: ${JSON.stringify(toolResult)}`,
                timestamp: new Date(),
              } as AgentMessage);
              
              console.log(`üîç Current messages after tool result:`, currentMessages.length);
              console.log(`üîç Last message:`, JSON.stringify(currentMessages[currentMessages.length - 1], null, 2));

            } catch (error) {
              console.error(`‚ùå Erro ao executar tool ${toolCall.toolName}:`, error);
              
              // Adicionar erro da tool √†s mensagens
               // Converter tool error para string simples
               const toolErrorString = `Tool ${toolCall.toolName} error: ${error instanceof Error ? error.message : "Erro desconhecido"}`;
               currentMessages.push({
                 role: 'assistant',
                 content: toolErrorString
               } as ModelMessage);

              // Adicionar erro da tool √† sess√£o
              session.messages.push({
                role: "assistant",
                content: `Tool ${toolCall.toolName} Error: ${error instanceof Error ? error.message : "Erro desconhecido"}`,
                timestamp: new Date(),
              } as AgentMessage);
            }
          }
          
          // Continue the loop to allow the AI agent to make more tool calls if needed
          console.log('üîÑ Tool calls executed, continuing to next iteration...');
          
          // Don't break here - let the AI agent decide if it needs more tools
        } else {
          // Se n√£o h√° tool calls, o AI agent terminou naturalmente
          console.log('üèÅ Nenhuma tool call detectada, AI agent terminou naturalmente');
          
          // Se j√° temos uma resposta de texto do AI agent, usar ela
          if (result.text && result.text.trim()) {
            finalResponseText = result.text;
            console.log('üìù Usando resposta de texto do AI agent:', finalResponseText);
          } else {
            // Fallback: for√ßar uma resposta textual final
            console.log('‚ö†Ô∏è AI agent n√£o forneceu resposta de texto, for√ßando resposta final...');
            
            // Adicionar mensagem especial para for√ßar resposta textual
            currentMessages.push({
              role: "user",
              content: "Agora forne√ßa uma resposta textual amig√°vel ao usu√°rio baseada nas a√ß√µes que voc√™ executou. N√ÉO use mais tools."
            });

            const finalResult = await generateText({
              model: llmModel,
              messages: currentMessages,
              temperature: 0.7,
            });

            finalResponseText = finalResult.text;
            console.log('üìù Resposta final for√ßada gerada:', finalResponseText);
          }
          
          break;
        }
      }



      // Adicionar resposta do assistente
      const assistantMsg: AgentMessage = {
        role: "assistant",
        content: finalResponseText,
        timestamp: new Date(),
      };
      await this.sessionService.addMessage(sessionId, assistantMsg, context?.userId);
      session.messages.push(assistantMsg);
      console.log("‚ûï Resposta do assistente adicionada √† sess√£o");

      // Limitar hist√≥rico de mensagens (manter √∫ltimas 20)
      if (session.messages.length > 20) {
        session.messages = session.messages.slice(-20);
        console.log("üóÇÔ∏è Hist√≥rico limitado a 20 mensagens");
      }

      console.log("‚úÖ ProcessMessage conclu√≠do com sucesso");
      return finalResponseText;
    } catch (error) {
      console.error("‚ùå Erro ao processar mensagem:", error);
      console.error("‚ùå Stack trace:", error instanceof Error ? error.stack : "Stack n√£o dispon√≠vel");
      return "Desculpe, ocorreu um erro interno. Tente novamente em alguns instantes ou entre em contato conosco pelo telefone (11) 1234-5678.";
    }
  }

  // Processar mensagem com streaming
  async streamMessage(sessionId: string, userMessage: string, context?: { cartId?: string; userId?: string; user?: any; currentPage?: string }) {
    // Valida√ß√£o de entrada
    if (!sessionId || typeof sessionId !== "string" || sessionId.trim().length === 0) {
      const error = new Error("SessionId √© obrigat√≥rio e deve ser uma string n√£o vazia");
      logger.error("Erro de valida√ß√£o no streamMessage:", error);
      throw error;
    }

    if (!userMessage || typeof userMessage !== "string" || userMessage.trim().length === 0) {
      const error = new Error("Mensagem do usu√°rio √© obrigat√≥ria e deve ser uma string n√£o vazia");
      logger.error("Erro de valida√ß√£o no streamMessage:", error);
      throw error;
    }

    if (userMessage.length > 10000) {
      const error = new Error("Mensagem do usu√°rio muito longa (m√°ximo 10000 caracteres)");
      logger.error("Erro de valida√ß√£o no streamMessage:", error);
      throw error;
    }

    try {
      console.log("üéØ StreamMessage iniciado para sess√£o:", sessionId);
      console.log("üí¨ Mensagem original do usu√°rio:", userMessage);
      console.log("üîß Contexto fornecido:", context);

      // Reescrever mensagem se habilitado
      let processedMessage = userMessage;
      if (this.llmConfig.enableMessageRewriter) {
        const rewriteResult = await conditionalRewriteMessage(userMessage, this.llmConfig);
        processedMessage = rewriteResult.message;
        if (rewriteResult.wasRewritten) {
          logger.debug("Mensagem reescrita", { original: userMessage, rewritten: processedMessage });
        }
      }

      const session = await this.getSession(sessionId);
      logger.debug("Sess√£o obtida", { sessionId, messageCount: session.messages.length });

      // Atualizar contexto se fornecido
      if (context) {
        await this.sessionService.updateSessionContext(sessionId, { ...session.context, ...context });
        logger.debug("Contexto atualizado", { sessionId, context });
      }

      // Adicionar mensagem do usu√°rio
      const userMsg: AgentMessage = {
        role: "user",
        content: processedMessage,
        timestamp: new Date(),
      };
      await this.sessionService.addMessage(sessionId, userMsg, context?.userId);
      session.messages.push(userMsg);
      logger.debug("Mensagem do usu√°rio adicionada", { sessionId });

      // Preparar mensagens para o LLM
      const messages: ModelMessage[] = [{ role: "system", content: SYSTEM_PROMPT }, ...this.convertMessages(session.messages)];
      logger.debug("Mensagens preparadas para LLM", { count: messages.length });

      // Gerar resposta com streaming (usando fallback)
      const llmModel = await createLLMModelWithFallback(this.llmConfig);
      logger.debug("Modelo LLM criado", { hasModel: !!llmModel, toolCount: Object.keys(allTools).length });

      // Definir sessionId no contexto global para as tools
      setGlobalContext("sessionId", sessionId);
      if (context) {
        if (context.cartId) setGlobalContext("cartId", context.cartId);
        if (context.userId) {
          setGlobalContext("userId", context.userId);
          logger.debug("UserId definido no contexto", { userId: context.userId });
        }
        if (context.user) {
          setGlobalContext("user", context.user);
          logger.debug("User definido no contexto", { user: context.user });
        }
        if (context.currentPage) setGlobalContext("currentPage", context.currentPage);
      }
      logger.debug("Contexto global configurado", { sessionId });

      // Detectar se a mensagem requer tools obrigatoriamente
      const requiresTools = this.shouldForceToolUsage(processedMessage);
      logger.debug("Iniciando processamento", {
        sessionId,
        message: processedMessage,
        requiresTools,
        toolCount: Object.keys(allTools).length,
      });

      const result = streamText({
        model: llmModel,
        messages,
        tools: allTools,
        temperature: this.llmConfig.temperature || 0.7,
        toolChoice: "auto", // Always use "auto" to allow text generation after tools
      });

      // Processar tool calls do resultado com suporte a m√∫ltiplas execu√ß√µes
      let executionCount = 0;
      const maxExecutions = 3; // Limite para evitar loops infinitos
      const productSearchTools = ["search_products", "get_promotional_products", "list_recommended_products", "get_best_sellers"];

      for await (const part of result.fullStream) {
        if (part.type === "tool-call") {
          executionCount++;
          logger.debug("Tool call executada", {
            toolName: part.toolName,
            execution: executionCount,
            toolCallId: part.toolCallId,
            args: (part as any).input,
          });

          try {
            logger.debug("Executando tool", { toolName: part.toolName });
            const tool = allTools[part.toolName as keyof typeof allTools];
            if (!tool || !tool.execute) {
              throw new Error(`Tool ${part.toolName} n√£o encontrada ou n√£o execut√°vel`);
            }
            const toolResult = await (tool.execute as any)((part as any).input);
            logger.debug("Tool executada com sucesso", {
              toolName: part.toolName,
              result: toolResult,
            });

            // N√ÉO adicionar resultado da tool √† sess√£o para evitar vazamento de informa√ß√µes t√©cnicas
            // Apenas fazer log interno para debugging

            // Armazenar tool result para processamento posterior no streaming
            logger.debug("Armazenando resultado da tool", {
              toolName: part.toolName,
              hasResult: !!toolResult,
              hasData: !!toolResult?.data,
              hasProducts: !!toolResult?.data?.products,
              productCount: toolResult?.data?.products?.length || 0,
            });

            // Tools ser√£o executadas naturalmente pelo LLM conforme o prompt
          } catch (error) {
            logger.error("Erro na execu√ß√£o da tool", {
              toolName: part.toolName,
              error: error instanceof Error ? error.message : error,
            });

            // N√ÉO adicionar erro da tool √† sess√£o para evitar vazamento de informa√ß√µes t√©cnicas
            // Apenas fazer log interno
          }
        } else if (part.type === "text-delta") {
          // Log silencioso para text-delta
        } else {
          logger.debug("Stream part processado", { type: part.type });
        }
      }

      logger.debug("Processamento conclu√≠do", {
        sessionId,
        totalMessages: session.messages.length,
      });

      return result;
    } catch (error) {
      logger.error("Erro ao processar mensagem com streaming:", {
        sessionId,
        userMessage: userMessage.substring(0, 100) + (userMessage.length > 100 ? "..." : ""),
        context,
        error:
          error instanceof Error
            ? {
                message: error.message,
                stack: error.stack,
                name: error.name,
              }
            : error,
      });

      // Error j√° logado pelo logger.error acima

      // Re-throw validation errors as-is
      if (error instanceof Error && error.message.includes("valida√ß√£o")) {
        throw error;
      }

      // For other errors, provide a more user-friendly message
      throw new Error("Erro interno ao processar mensagem. Tente novamente.");
    }
  }

  // Gerar resposta apenas textual sem tools
  async generateTextOnlyResponse(sessionId: string, userMessage: string, context?: { cartId?: string; userId?: string; user?: any; currentPage?: string }): Promise<string> {
    try {
      logger.info("Gerando resposta apenas textual", { sessionId, messageLength: userMessage.length });

      const session = await this.getSession(sessionId);

      // Preparar mensagens para o LLM
      const convertedMessages = this.convertMessages(session.messages);
      const currentMessages: ModelMessage[] = [
        { 
          role: "system", 
          content: `Voc√™ √© o assistente virtual da Farm√°cia Vanaci. Baseado no contexto da conversa anterior, forne√ßa uma resposta textual amig√°vel e concisa. 
          
          IMPORTANTE: 
          - N√ÉO use nenhuma ferramenta/tool
          - Apenas responda com texto natural
          - Seja amig√°vel e confirme as a√ß√µes j√° realizadas
          - Mantenha o tom profissional de farm√°cia` 
        },
        ...convertedMessages,
        { role: "user", content: userMessage }
      ];

      // Gerar resposta SEM tools
      const llmModel = await createLLMModelWithFallback(this.llmConfig);
      
      const result = await generateText({
        model: llmModel,
        messages: currentMessages,
        // N√ÉO incluir tools para for√ßar apenas resposta textual
        temperature: this.llmConfig.temperature || 0.7,
      });

      if (result.text && result.text.trim()) {
        logger.info("Resposta textual gerada com sucesso", { responseLength: result.text.length });
        return result.text.trim();
      } else {
        throw new Error("Nenhuma resposta textual foi gerada");
      }
    } catch (error) {
      logger.error("Erro ao gerar resposta textual", { sessionId, error });
      return "Perfeito! As a√ß√µes foram realizadas com sucesso. Verifique os itens adicionados acima.";
    }
  }

  // Obter hist√≥rico da sess√£o
  async getSessionHistory(sessionId: string): Promise<AgentMessage[]> {
    try {
      const session = await this.sessionService.getSession(sessionId);
      return session ? [...session.messages] : [];
    } catch (error) {
      logger.error("Erro ao obter hist√≥rico da sess√£o", { sessionId, error });
      return [];
    }
  }

  // Limpar sess√£o
  async clearSession(sessionId: string): Promise<void> {
    try {
      await this.sessionService.deleteSession(sessionId);
      sessionCache.delete(sessionId);
      logger.info("Sess√£o limpa com sucesso", { sessionId });
    } catch (error) {
      logger.error("Erro ao limpar sess√£o", { sessionId, error });
      throw new Error(`Falha ao limpar sess√£o: ${error instanceof Error ? error.message : "Erro desconhecido"}`);
    }
  }

  // Obter contexto da sess√£o
  async getSessionContext(sessionId: string): Promise<Record<string, any>> {
    try {
      const session = await this.sessionService.getSession(sessionId);
      return session ? { ...session.context } : {};
    } catch (error) {
      logger.error("Erro ao obter contexto da sess√£o", { sessionId, error });
      return {};
    }
  }

  // Atualizar configura√ß√£o do LLM
  updateLLMConfig(newConfig: Partial<ConfigLLMConfig>): void {
    this.llmConfig = { ...this.llmConfig, ...newConfig };
    validateLLMConfig(this.llmConfig.provider);
  }

  // Obter configura√ß√£o atual do LLM
  getLLMConfig(): ConfigLLMConfig {
    return { ...this.llmConfig };
  }
}

// Inst√¢ncia singleton do agente
let agentInstance: PharmacyAIAgent | null = null;

// Fun√ß√£o para obter inst√¢ncia do agente
export function getPharmacyAgent(config?: ConfigLLMConfig): PharmacyAIAgent {
  if (!agentInstance) {
    agentInstance = new PharmacyAIAgent(config);
  }
  return agentInstance;
}

// Fun√ß√£o utilit√°ria para processar mensagem rapidamente
export async function processUserMessage(
  sessionId: string,
  message: string,
  context?: { cartId?: string; userId?: string; user?: any; currentPage?: string },
  llmConfig?: ConfigLLMConfig
): Promise<string> {
  try {
    // Validar entrada
    if (!sessionId || typeof sessionId !== "string") {
      throw new Error("SessionId √© obrigat√≥rio e deve ser uma string");
    }

    if (!message || typeof message !== "string" || message.trim().length === 0) {
      throw new Error("Mensagem √© obrigat√≥ria e n√£o pode estar vazia");
    }

    if (message.length > 10000) {
      throw new Error("Mensagem muito longa (m√°ximo 10.000 caracteres)");
    }

    const agent = getPharmacyAgent(llmConfig);
    return await agent.processMessage(sessionId, message.trim(), context);
  } catch (error) {
    logger.error("Erro na fun√ß√£o processUserMessage", { sessionId, messageLength: message?.length, error });

    if (error instanceof Error && error.message.includes("obrigat√≥rio")) {
      throw error; // Re-throw validation errors
    }

    return "Desculpe, ocorreu um erro interno. Tente novamente em alguns instantes ou entre em contato conosco pelo telefone (11) 1234-5678.";
  }
}

// Exportar types e tools
export * from "./types";
export * from "./config";
export { cartTools, productTools, checkoutTools, navigationTools, budgetTools, extraTools };
